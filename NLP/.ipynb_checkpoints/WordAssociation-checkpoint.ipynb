{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a0f0df-eef5-4af5-991a-7b23718512c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import gensim\n",
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57974f9-4b53-47ff-be64-beddb846f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = r''\n",
    "dbSQL = ''\n",
    "user = ''\n",
    "pwd = ''\n",
    "MC0 = '''ABS AH- ALM BC- BL- CA- CAE CHG COM CU- FP- FW- GA- GBL GPP GUE HVC LBU LGR LIT MWT PLT PND PRD PWS RS- SCR SD- SDR SPP STB SW- TIC TRF UDT WST'''.split(' ')\n",
    "MC1 = '''ABS AF- AH- ALM BC- BL- CA- CAE CBA CCW CHG CND COM CU- ESP EXC FAT FG- FP- FW- GA- GUE GYP HVC LIT MWT PFC PJF PLT PRD RS- BCW SD- SDR SIS STB SW- TA- TIC TRF'''.split(' ')\n",
    "MC2 = '''ABS AF- AH- ALM BC- BL- CA- CAE CBA CCW CHG CND COM CU- ESP EXC FAT FG- FP- FW- GA- GUE GYP HVC LIT MWT PFC PJF PLT PRD RS- BCW SD- SDR SIS STB SW- TA- TIC TRF'''.split(' ')\n",
    "MC3 = '''ABS AF- AH- ALM BC- BL- CA- CAE CBA CCW CHG CND COM CU- ESP EXC FAT FG- FP- FW- GA- GUE GYP HVC LIT MWT PFC PJF PLT PRD RS- SCR SD- SDR SIS STB SW- TA- TIC TRF'''.split(' ')\n",
    "#Consider adding MC00X in fron to all above in code os I don't need to do it later in teh code :)\n",
    "#I will do this in an algorithm later by pulling in MaximoDW.dbo.Locations and grabbing DISTINCT SUBSTRING(LOCATION, 4, 8) but right now i'm lazy\n",
    "where = ''\n",
    "for l in MC0: where += f'OR LOCATION LIKE \\'MC000{l}%\\' '\n",
    "for l in MC1: where += f'OR LOCATION LIKE \\'MC001{l}%\\' '\n",
    "for l in MC2: where += f'OR LOCATION LIKE \\'MC002{l}%\\' '\n",
    "for l in MC3: where += f'OR LOCATION LIKE \\'MC003{l}%\\' '\n",
    "where = where[3:]\n",
    "maximoSelect = f\"\"\"SELECT [\n",
    "\n",
    "\"\"\"\n",
    "woSelect= f\"\"\"SELECT [WONUM]\n",
    "      ,[LOCATION]\n",
    "      ,[DESCRIPTION]\n",
    "  FROM [Generation].[agent].[MaximoWorkOrders]\n",
    "  Where cast(STATUSDATE as date) > '01/01/2020'\n",
    "\"\"\"  #and LOC = 'MC'\n",
    "#  And ({where})\"\"\"\n",
    "\n",
    "#getting data and then relableing maximo location to higher level equipment name\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+host+';DATABASE='+dbSQL+';UID='+user+';PWD='+ pwd)\n",
    "WOdata = pd.read_sql(woSelect, cnxn)\n",
    "#for key in MC0: WOdata.LOCATION[WOdata.LOCATION.str.startswith('MC000' + key)] = 'MC000' + MC0[MC0.index(key)]\n",
    "#for key in MC1: WOdata.LOCATION[WOdata.LOCATION.str.startswith('MC001' + key)] = 'MC001' + MC1[MC1.index(key)]\n",
    "#for key in MC2: WOdata.LOCATION[WOdata.LOCATION.str.startswith('MC002' + key)] = 'MC002' + MC2[MC2.index(key)]\n",
    "#for key in MC3: WOdata.LOCATION[WOdata.LOCATION.str.startswith('MC003' + key)] = 'MC003' + MC3[MC3.index(key)]\n",
    "WOdata = WOdata.drop(columns=['WONUM'])\n",
    "WOdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6239505-9a67-4ef6-94e3-8ccae6e506f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WOdata['Edited1'] = [list() for x in range(len(WOdata.index))]\n",
    "WOdata['Edited2'] = [list() for x in range(len(WOdata.index))]\n",
    "\n",
    "def processText(text):\n",
    "    #text_tokens = word_tokenize(text)\n",
    "    text_tokens = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(text)\n",
    "    text_tokens = [word for word in text_tokens if not word in stop_words]  ##Remove Stop Words\n",
    "    text_tokens = [word.lower() for word in text_tokens]\n",
    "    #text_tokens = [ps.stem(word) for word in text_tokens] #Stem Words\n",
    "    #text_tokens = [word for word in text_tokens if len(word) > 2] #Removing noise\n",
    "    #text_tokens = [word for word in text_tokens if word.isalpha()] #Remove Punctuation\n",
    "    #text_tokens = [ele for ele in text_tokens if ele.strip()] #remove empty spaces in list\n",
    "    return text_tokens\n",
    "#Applying Text Processing\n",
    "WOdata['Edited1'] = WOdata['DESCRIPTION'].apply(processText)\n",
    "WOdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "953c9f1b-b975-43d2-aebc-7aed304d8e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a corpus out of our collection of items\n",
    "from gensim import corpora\n",
    "texts = WOdata['Edited1'].to_list()\n",
    "frequency = defaultdict(int)\n",
    "'''\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "'''\n",
    "dictionary = corpora.Dictionary(WOdata['Edited1'])\n",
    "corpus = [dictionary.doc2bow(text) for text in WOdata['Edited1']]\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af78c38b-804b-4afd-a5b3-ae705358c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save('testDict.cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e18320a-8c31-4471-9e25-55ffdfb3239e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/8132 is pm\n",
      "word #1/8132 is 1\n",
      "word #2/8132 is 2\n",
      "word #3/8132 is weekly\n",
      "word #4/8132 is unit\n",
      "word #5/8132 is 3\n",
      "word #6/8132 is 4\n",
      "word #7/8132 is daily\n",
      "word #8/8132 is monthly\n",
      "word #9/8132 is oil\n",
      "word #10/8132 is and\n",
      "word #11/8132 is pump\n",
      "word #12/8132 is inspections\n",
      "word #13/8132 is air\n",
      "word #14/8132 is check\n",
      "word #15/8132 is checks\n",
      "word #16/8132 is inspection\n",
      "word #17/8132 is a\n",
      "word #18/8132 is clean\n",
      "word #19/8132 is needs\n",
      "word #20/8132 is inspect\n",
      "word #21/8132 is units\n",
      "word #22/8132 is valve\n",
      "word #23/8132 is to\n",
      "word #24/8132 is on\n",
      "word #25/8132 is lubrication\n",
      "word #26/8132 is b\n",
      "word #27/8132 is u\n",
      "word #28/8132 is system\n",
      "word #29/8132 is c\n",
      "word #30/8132 is water\n",
      "word #31/8132 is 0\n",
      "word #32/8132 is conveyor\n",
      "word #33/8132 is 12\n",
      "word #34/8132 is coal\n",
      "word #35/8132 is u1\n",
      "word #36/8132 is grease\n",
      "word #37/8132 is mill\n",
      "word #38/8132 is ash\n",
      "word #39/8132 is u3\n",
      "word #40/8132 is fan\n",
      "word #41/8132 is annual\n",
      "word #42/8132 is tc1\n",
      "word #43/8132 is leaking\n",
      "word #44/8132 is change\n",
      "word #45/8132 is tc2\n",
      "word #46/8132 is replace\n",
      "word #47/8132 is motor\n",
      "word #48/8132 is in\n",
      "word #49/8132 is quarterly\n",
      "word #50/8132 is not\n",
      "word #51/8132 is of\n",
      "word #52/8132 is u4\n",
      "word #53/8132 is 13\n",
      "word #54/8132 is alarm\n",
      "word #55/8132 is hvac\n",
      "word #56/8132 is pumps\n",
      "word #57/8132 is filters\n",
      "word #58/8132 is u2\n",
      "word #59/8132 is line\n",
      "word #60/8132 is outage\n",
      "word #61/8132 is inlet\n",
      "word #62/8132 is filter\n",
      "word #63/8132 is out\n",
      "word #64/8132 is room\n",
      "word #65/8132 is for\n",
      "word #66/8132 is r\n",
      "word #67/8132 is need\n",
      "word #68/8132 is the\n",
      "word #69/8132 is leak\n",
      "word #70/8132 is has\n",
      "word #71/8132 is equipment\n",
      "word #72/8132 is is\n",
      "word #73/8132 is nox\n",
      "word #74/8132 is lube\n",
      "word #75/8132 is cooling\n",
      "word #76/8132 is scr\n",
      "word #77/8132 is tank\n",
      "word #78/8132 is see\n",
      "word #79/8132 is monitor\n",
      "word #80/8132 is service\n",
      "word #81/8132 is feeder\n",
      "word #82/8132 is bi\n",
      "word #83/8132 is sample\n",
      "word #84/8132 is ts\n",
      "word #85/8132 is flow\n",
      "word #86/8132 is turbine\n",
      "word #87/8132 is d\n",
      "word #88/8132 is calibration\n",
      "word #89/8132 is cems\n",
      "word #90/8132 is packing\n",
      "word #91/8132 is shelter\n",
      "word #92/8132 is pjff\n",
      "word #93/8132 is replaced\n",
      "word #94/8132 is cem\n",
      "word #95/8132 is battery\n",
      "word #96/8132 is 6\n",
      "word #97/8132 is fgd\n",
      "word #98/8132 is all\n",
      "word #99/8132 is blower\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import gensim.models\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences=WOdata['Edited1'].to_list())\n",
    "wv = model.wv\n",
    "#vec_king = model.wv['Coal']\n",
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index ==100:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6b44a42-e2c2-4114-ada9-8e65caa5c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'weekly'\n",
    "#wv.most_similar(target)\n",
    "good_count = 0\n",
    "for t in texts:\n",
    "    if (wv.wmdistance(target, t) < .8):\n",
    "        good_count += 1\n",
    "        print(wv.wmdistance(target, t) )\n",
    "        print(t)\n",
    "    if(good_count > 10):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a09a0-a122-4479-9c29-d99be11d157b",
   "metadata": {},
   "source": [
    "Training off Quest rather than Work Order Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b6a53a-2539-428c-99f4-16fc5e7acc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark/.local/lib/python3.8/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size:  Name              54313\n",
      "DrawingTextAll    54313\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query1 = \"\"\"select [Name], [DrawingTextAll]  from [Generation].[quest].[Drawings] WHERE DrawingTextAll IS NOT NULL\"\"\"\n",
    "queryProperties ={\"user\": \"\", \"password\": \"\", \"driver\":\"org.postgresql.Driver\",\"spark.jars\":\"file:/home/postgresTest/postgresql-42.2.9.jar\",\"spark.executor.extraClassPath\":\"/home/postgresTest/postgresql-42.2.9.jar\",\"spark.driver.extraClassPath\":\"/home/postgresTest/postgresql-42.2.9.jar\", 'partitionColumn':'TAGID_PI', 'lowerBound': '1100000000' , 'upperBound': '1510890005', 'numPartitions':'80', 'fetchsize':'100000'}\n",
    "server = 'VMGENENG5' \n",
    "database = 'Generation' \n",
    "username = 'GENENG' \n",
    "password = 'U+RrPP\"ks2]<#2{6'\n",
    "cnxn = pyodbc.connect('DRIVER=/opt/microsoft/msodbcsql17/lib64/libmsodbcsql-17.9.so.1.1;SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "#You may need to change the libmsodbcsql-17.8.s0.1.1 if we update it. Open a terminal cd out of /u01/ and start going down opt\n",
    "global questData\n",
    "questData = pd.read_sql(query1,cnxn)\n",
    "print(\"Data size: \", questData.count())\n",
    "cnxn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005960e-4f8a-423a-a659-83d92efed4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "questData['Edited1'] = [list() for x in range(len(questData.index))]\n",
    "questData['Edited1'] = questData['DrawingTextAll'].apply(processText)\n",
    "\n",
    "questData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624c2b32-8bf8-4be4-871e-fa1cc17c63f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a corpus out of our collection of items\n",
    "from gensim import corpora\n",
    "questTexts = questData['Edited1'].to_list()\n",
    "frequency = defaultdict(int)\n",
    "'''\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "'''\n",
    "dictionary = corpora.Dictionary(questData['Edited1'])\n",
    "dictionary.filter_extremes()\n",
    "corpus = [dictionary.doc2bow(text) for text in questData['Edited1']]\n",
    "#lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "218a007a-a0d3-4405-bb13-2bc275d62485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/105549 is 2\n",
      "word #1/105549 is 1\n",
      "word #2/105549 is 4\n",
      "word #3/105549 is ee\n",
      "word #4/105549 is 3\n",
      "word #5/105549 is 7\n",
      "word #6/105549 is a\n",
      "word #7/105549 is no\n",
      "word #8/105549 is e\n",
      "word #9/105549 is 0\n",
      "word #10/105549 is 5\n",
      "word #11/105549 is to\n",
      "word #12/105549 is 6\n",
      "word #13/105549 is 8\n",
      "word #14/105549 is s\n",
      "word #15/105549 is of\n",
      "word #16/105549 is for\n",
      "word #17/105549 is c\n",
      "word #18/105549 is ae\n",
      "word #19/105549 is f\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import gensim.models\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences=questTexts)\n",
    "wv = model.wv\n",
    "#vec_king = model.wv['Coal']\n",
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index ==20:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9adb5948-3e6c-4cbf-bb98-51a11e89f92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('retrofit', 0.7165215015411377),\n",
       " ('fgo', 0.7153223752975464),\n",
       " ('pgd', 0.6869065165519714),\n",
       " ('retrof', 0.6608300805091858),\n",
       " ('handung', 0.6589170694351196),\n",
       " ('reconnect', 0.6557502746582031),\n",
       " ('retpofit', 0.6391232013702393),\n",
       " ('fgod', 0.6194508075714111),\n",
       " ('egd', 0.6157587170600891),\n",
       " ('broan', 0.6097511649131775)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'fgd'\n",
    "wv.most_similar(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b4fc16-b2a0-43c4-a4a4-75180f725d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e9e5f-fa01-4f9d-bdcf-c9165e4f8d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

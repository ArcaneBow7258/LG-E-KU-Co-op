{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59feeb56-ce37-40a8-85dd-a90ad2778acd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Goals</h3>\n",
    "<ul>\n",
    "    <li> Remove as much noise from Quest Drawing Text as possible. <b> Uses word Frequency </b></li>    \n",
    "    <li> Find a way to correct spelling or something like that</li>   \n",
    "    <li> Create a preliinary way of having users access the quest data</li> \n",
    "    <li> FIND ESTIMATED TIMINGS of searching our Quest Database</li> \n",
    "</ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80eae62-e57a-4b3a-8031-cf9a60d23178",
   "metadata": {},
   "source": [
    "<h2>Libraries + Settings + Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "195961b7-2149-4c83-a0d3-06dfd196957e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "def processText(text):\n",
    "    #text_tokens = word_tokenize(text)\n",
    "    text_tokens = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(text)\n",
    "    text_tokens = [word for word in text_tokens if not word in stop_words]  ##Remove Stop Words\n",
    "    text_tokens = [word.lower() for word in text_tokens]\n",
    "    #text_tokens = [ps.stem(word) for word in text_tokens] #Stem Words\n",
    "    #text_tokens = [word for word in text_tokens if len(word) > 2] #Removing noise\n",
    "    #text_tokens = [word for word in text_tokens if word.isalpha()] #Remove Punctuation\n",
    "    #text_tokens = [ele for ele in text_tokens if ele.strip()] #remove empty spaces in list\n",
    "    return text_tokens \n",
    "#might move below functions into above process text\n",
    "def removeStops(text): #Remove stop words\n",
    "    filtered = []\n",
    "    for word in text:\n",
    "        word = word.lower()\n",
    "        #temp = [(jaccard_distance(set(ngrams(word, 2)), set(ngrams(w, 2))),w) for w in correct_spellings if w[0]==word[0]]\n",
    "        #sorted(temp, key = lambda val:val[0])[0][1]\n",
    "        \n",
    "        if word not in stop_words:\n",
    "            filtered.append(word)\n",
    "    return filtered\n",
    "def stemming(text): # Remove stems from words\n",
    "    words = []\n",
    "    for word in text:\n",
    "        words.append(stemmer.stem(word))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077456c1-2fd0-4026-b60e-1e998de7a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"Select [Name], [DrawingTextAll]  from [Generation].[quest].[Drawings] WHERE DrawingTextAll IS NOT NULL\"\"\"\n",
    "queryProperties ={\"user\": \"\", \"password\": \"\", \"driver\":\"org.postgresql.Driver\",\"spark.jars\":\"file:/home/postgresTest/postgresql-42.2.9.jar\",\"spark.executor.extraClassPath\":\"/home/postgresTest/postgresql-42.2.9.jar\",\"spark.driver.extraClassPath\":\"/home/postgresTest/postgresql-42.2.9.jar\", 'partitionColumn':'TAGID_PI', 'lowerBound': '1100000000' , 'upperBound': '1510890005', 'numPartitions':'80', 'fetchsize':'100000'}\n",
    "server = '' \n",
    "database = '' \n",
    "username = '' \n",
    "password = '\n",
    "cnxn = pyodbc.connect('DRIVER=/opt/microsoft/msodbcsql17/lib64/libmsodbcsql-17.10.so.1.1;SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "\n",
    "#You may need to change the libmsodbcsql-17.8.s0.1.1 if we update it. Open a terminal cd out of /u01/ and start going down opt\n",
    "\n",
    "p = pd.read_sql(query1,cnxn)\n",
    "p['DrawingTextAll'][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f8ba07-5597-47c6-b4ba-36c96bd80a02",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Data Import </h2>\n",
    "<ul>\n",
    "    <li> Only work orders past 01/01/2020 </li>\n",
    "    <li> Loading top 1000 Quest Items to not be super slow. Later need to change to test timings </li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a8094aa-8b99-45cb-9e9d-4fa3256227f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark/.local/lib/python3.8/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "/home/spark/.local/lib/python3.8/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "host = r''\n",
    "dbSQL = ''\n",
    "user = ''\n",
    "pwd = ''\n",
    "#Work Orders\n",
    "\n",
    "woSelect= f\"\"\"SELECT [WONUM]\n",
    "      ,[LOCATION]\n",
    "      ,[DESCRIPTION]\n",
    "  FROM [Generation].[agent].[MaximoWorkOrders]\n",
    "  Where cast(STATUSDATE as date) > '01/01/2020'\n",
    "\"\"\" \n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+host+';DATABASE='+dbSQL+';UID='+user+';PWD='+ pwd)\n",
    "WOdata = pd.read_sql(woSelect, cnxn)\n",
    "WOdata = WOdata.drop(columns=['WONUM'])\n",
    "\n",
    "WOdata['Edited1'] = [list() for x in range(len(WOdata.index))]\n",
    "WOdata['Edited1'] = WOdata['DESCRIPTION'].apply(processText)\n",
    "\n",
    "\n",
    "#Quest\n",
    "query1 = \"\"\"Select TOP(1000) [Name], [DrawingTextAll]  from [Generation].[quest].[Drawings] WHERE DrawingTextAll IS NOT NULL\"\"\"\n",
    "queryProperties ={\"user\": \"GENENG\", \"password\": \"postgres\", \"driver\":\"org.postgresql.Driver\",\"spark.jars\":\"file:/home/postgresTest/postgresql-42.2.9.jar\",\"spark.executor.extraClassPath\":\"/home/postgresTest/postgresql-42.2.9.jar\",\"spark.driver.extraClassPath\":\"/home/postgresTest/postgresql-42.2.9.jar\", 'partitionColumn':'TAGID_PI', 'lowerBound': '1100000000' , 'upperBound': '1510890005', 'numPartitions':'80', 'fetchsize':'100000'}\n",
    "server = '' \n",
    "database = '' \n",
    "username = '' \n",
    "password = ''\n",
    "cnxn = pyodbc.connect('DRIVER=/opt/microsoft/msodbcsql17/lib64/libmsodbcsql-17.10.so.1.1;SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "#You may need to change the libmsodbcsql-17.8.s0.1.1 if we update it. Open a terminal cd out of /u01/ and start going down opt\n",
    "global questData\n",
    "questData = pd.read_sql(query1,cnxn)\n",
    "questData['Edited1'] = [list() for x in range(len(questData.index))]\n",
    "questData['Edited1'] = questData['DrawingTextAll'].apply(processText)\n",
    "\n",
    "cnxn.close()\n",
    "\n",
    "\n",
    "#questData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf841de-f5ed-4736-a4a3-67ca6cb74dcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Getting Word Frequency from WO</h2>\n",
    "<ul> <li> Running a spellchecker on our words as well so we get correct spellings before we add to dictionary </li>\n",
    "    <li> We can afford to use a more verbose spellchecker since we have lower amount of words</li>\n",
    "    \n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96a36fec-4ee6-4c9f-afd8-4a28ba9847f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LOCATION', 'DESCRIPTION', 'Edited1', 'Score'], dtype='object')\n",
      "tokenize\n",
      "stops + stemming\n",
      "spelling\n",
      "words i'm correcting 17989\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "\n",
    "spell = SpellChecker(distance = 2)\n",
    "#spell.word_frequency.load_dictionary(\"WOWordFreq.json\")\n",
    "\n",
    "\n",
    "print(WOdata.columns)\n",
    "#Aggregating Columns to one list\n",
    "woText = WOdata.groupby(lambda _ : True)['DESCRIPTION'].transform(lambda x : ' '.join(x)).iat[0]\n",
    "\n",
    "print('tokenize')\n",
    "woText = nltk.tokenize.RegexpTokenizer('[A-Z]\\w+').tokenize(woText)\n",
    "\n",
    "print('stops + stemming')\n",
    "woText = removeStops(woText)\n",
    "# stemmign takes a hella long time bro\n",
    "#woText = stemming(woText)\n",
    "\n",
    "\n",
    "#print('\\n\\n frequency')\n",
    "woText = FreqDist(woText)\n",
    "export = pd.DataFrame(list(woText.items()), columns = [\"Word\",\"Frequency\"])\n",
    "\n",
    "#spell correction\n",
    "print('spelling')\n",
    "print('words i\\'m correcting',len(export['Word']))\n",
    "#We spell correct after aggregating to freq dist to avoid repeat and saving time from 160k wrods to 18k\n",
    "#and we reaggregate with summnation\n",
    "#export['Word'] = export['Word'].apply(spell.correction)\n",
    "#export = export.groupby(['Word']).sum()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89da4a9-bedc-4dc2-93a1-40234ab2c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export = pd.read_csv(\"SCWOWordFreq.txt\", sep=' ', header = None)\n",
    "#export = pd.read_csv(\"words/SCWOWordFreq.txt\", sep=' ', header = None)\n",
    "\n",
    "export['Word']= export[0]\n",
    "export['Frequency'] = export.astype({1: 'int64'})[1]\n",
    "export = export[['Word', 'Frequency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5cd50326-d517-4fae-b19b-05a88a390e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>inspections</td>\n",
       "      <td>18177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>oil</td>\n",
       "      <td>16516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>pump</td>\n",
       "      <td>15796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111</td>\n",
       "      <td>air</td>\n",
       "      <td>15602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>908</td>\n",
       "      <td>checks</td>\n",
       "      <td>14342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>5026</td>\n",
       "      <td>guards</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>192</td>\n",
       "      <td>term</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>128</td>\n",
       "      <td>properly</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>4441</td>\n",
       "      <td>amps</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>971</td>\n",
       "      <td>glass</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index         Word  Frequency\n",
       "0      258  inspections      18177\n",
       "1       99          oil      16516\n",
       "2       59         pump      15796\n",
       "3      111          air      15602\n",
       "4      908       checks      14342\n",
       "..     ...          ...        ...\n",
       "987   5026       guards        202\n",
       "988    192         term        202\n",
       "989    128     properly        201\n",
       "990   4441         amps        201\n",
       "991    971        glass        201\n",
       "\n",
       "[992 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export.hist(column=['Frequency'], range= (10,40))\n",
    "#Cutting depending on frequency\n",
    "print('cutting')\n",
    "\n",
    "WOWordFreq = export\n",
    "WOWordFreq = WOWordFreq[WOWordFreq['Frequency'] < 20000]\n",
    "WOWordFreq = WOWordFreq[WOWordFreq['Frequency'] > 200]\n",
    "\n",
    "WOWordFreq = WOWordFreq.sort_values(\"Frequency\", ascending = False)\n",
    "WOWordFreq = WOWordFreq.reset_index()\n",
    "'''\n",
    "print('saving export sincei  don\\'t want to re process')\n",
    "with open('SCWOWordFreq.txt', 'w') as f:\n",
    "    #temp = export.reset_index() #use if you get it from FreqDist,\n",
    "    temp = export\n",
    "    for w in range(len(temp)):\n",
    "       f.write(str(temp['Word'][w]) + \" \" + str(temp['Frequency'][w]) + '\\n')'''\n",
    "\n",
    "WOWordFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d0327a6d-0a7b-4032-953b-35fbd67c3498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>pm</td>\n",
       "      <td>149192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>weekly</td>\n",
       "      <td>39019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>unit</td>\n",
       "      <td>33776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>daily</td>\n",
       "      <td>24731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>monthly</td>\n",
       "      <td>20743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>inspections</td>\n",
       "      <td>18177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>oil</td>\n",
       "      <td>16516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>pump</td>\n",
       "      <td>15796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>air</td>\n",
       "      <td>15602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>checks</td>\n",
       "      <td>14342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>check</td>\n",
       "      <td>14031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>inspection</td>\n",
       "      <td>12680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>inspect</td>\n",
       "      <td>11742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>clean</td>\n",
       "      <td>11465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>units</td>\n",
       "      <td>10880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>lubrication</td>\n",
       "      <td>10019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>system</td>\n",
       "      <td>8507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>u1</td>\n",
       "      <td>8216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>grease</td>\n",
       "      <td>8028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>conveyor</td>\n",
       "      <td>8011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  Frequency\n",
       "180            pm     149192\n",
       "1877       weekly      39019\n",
       "21           unit      33776\n",
       "1590        daily      24731\n",
       "907       monthly      20743\n",
       "258   inspections      18177\n",
       "99            oil      16516\n",
       "59           pump      15796\n",
       "111           air      15602\n",
       "908        checks      14342\n",
       "846         check      14031\n",
       "661    inspection      12680\n",
       "774       inspect      11742\n",
       "249         clean      11465\n",
       "382         units      10880\n",
       "1879  lubrication      10019\n",
       "9          system       8507\n",
       "34             u1       8216\n",
       "1396       grease       8028\n",
       "759      conveyor       8011"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export.sort_values(\"Frequency\", ascending = False).head(20)\n",
    "#export.hist(column=['Frequency'], range= (100,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdfbc12-72b0-47f5-ad1d-092b2bbca67e",
   "metadata": {},
   "source": [
    "<h2> Setting up SymSpell for Spell Checker </h2>\n",
    "<ol> <li> Vocab comes from either A. WO Word Frequency or B. Library's prebuilt, or C. Combined </li>\n",
    "    <li> SymSpell is the fastest, but performs the least amount of transformations to find words </li>\n",
    "    <li> Consider condensing words, ie turning aaaaaa to aa </li>\n",
    "    <li> Looking to remove nonwords post spellchecked </li>\n",
    "    <li> Some test code to work on a singular drawing </li>  \n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b1566989-8651-4c3a-ab23-cc3ed215d90f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "import json\n",
    "sym_spell = SymSpell()\n",
    "\n",
    "#Default \n",
    "#sym_spell.load_dictionary(\"SymSpellDict_en_82_765.txt\", 0, 1)\n",
    "'''\n",
    "with open('WOWordFreq.txt', 'w') as f:\n",
    "    for w in range(len(WOWordFreq)):\n",
    "        f.write(str(WOWordFreq['Word'][w]) + \" \" + str(WOWordFreq['Frequency'][w]) + '\\n')\n",
    "    '''\n",
    "corpus_path = \"words/CutWOWordFreq.txt\"\n",
    "sym_spell.create_dictionary(corpus_path)\n",
    "#print(sym_spell.words)\n",
    "\n",
    "#Wait this is uneceessary - Alvin 9/15/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eba03162-0b99-46c9-ade5-a517bf9115e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make, copy SymSpellDict_en_82_765.txt as CombinedFreq.txt and run below code\n",
    "#need to remake it\n",
    "'''\n",
    "#Careful you need to fix it in the middle and write 1 extra newline at bottom\n",
    "with open(\"CombinedFreq.txt\", 'a') as f:\n",
    "    for w in range(len(WOWordFreq)):\n",
    "        f.write(str(WOWordFreq['Word'][w] + \" \" + str(WOWordFreq['Frequency'][w]) + '\\n'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4398d1a0-852b-4f5a-9a95-3b0cdcaa3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy import SymSpell, Verbosity\n",
    "from nltk.corpus import words\n",
    "sym_spell = SymSpell()\n",
    "#sym_spell.load_dictionary(\"SymSpellDict_en_82_765.txt\", 0, 1)\n",
    "sym_spell.load_dictionary(\"words/cutWOWordFreq.txt\", 0, 1)\n",
    "#sym_spell.load_dictionary(\"CombinedFreq.txt\", 0, 1) #takes a while sicne it has to iterate through more\n",
    "questData['Edited2'] = questData['Edited1'].apply(' '.join)\n",
    "probe = 1\n",
    "spellingTestList = questData['Edited2'][probe]\n",
    "def spellChecker(text):\n",
    "    text = text.split(' ')\n",
    "    final = ''\n",
    "    for w in range(len(text)):\n",
    "        if len(text[w]) != 1: #skipping single letters pray it doesn't matter.\n",
    "            suggestions = sym_spell.lookup(text[w].lower(), Verbosity.CLOSEST, max_edit_distance=2, ignore_token = None,   include_unknown=True)\n",
    "            for suggestion in suggestions:\n",
    "                #I would love to check for words that are actualyl english but the time it takes is rather.. long\n",
    "                #if str(suggestion).split(',')[0] in words.words()\n",
    "                final = final + str(suggestion).split(',')[0] + ' '\n",
    "                break\n",
    "    return final\n",
    "\n",
    "#single testing\n",
    "spellingTestList = spellChecker(spellingTestList)\n",
    "print(questData['Name'][probe])\n",
    "print(questData['Edited2'][probe])\n",
    "print(spellingTestList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b8daf524-abd3-42eb-a217-dec5a40352f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'gravimetric' in export['Word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3c72a88-54f2-412a-8204-c6785a8b3782",
   "metadata": {},
   "outputs": [],
   "source": [
    "questData['spellChecked'] = questData['Edited2'].apply(spellChecker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba700f80-0c05-4e33-9cd6-d5dc9a68f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "questData['spellChecked'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e93eaa8c-9691-4b66-84f1-a6a38f92a7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom, 3, 0\n"
     ]
    }
   ],
   "source": [
    "for suggestion in sym_spell.lookup('custom'.lower(), Verbosity.CLOSEST, max_edit_distance=2,  include_unknown=True):\n",
    "    print(suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdbb84-3f32-4290-b495-a2a22031ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "WOWordFreq['Frequency'][WOWordFreq['Word'].to_list().index('channel')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1684aa76-d5d8-41f7-9c93-32e70b4d427b",
   "metadata": {},
   "source": [
    "<h2>Pyspellchecker</h2>\n",
    "<ul><li>Gotta say pyspellchecker is pretty slow, but probably best bet if you want good quality?\n",
    "    </li></ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc961bb0-d004-4071-8307-8d98bc9311ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WOWordFreq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-a6a162a84a1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'WOWordFreq.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWOWordFreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\\"{WOWordFreq['Word'][w]}\\\":{str(WOWordFreq['Frequency'][w])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWOWordFreq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'WOWordFreq' is not defined"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "#I can't believe pandas json formatting sucks and doesn't work and i'm too lazy to work around it.\n",
    "with open('WOWordFreq.json', 'w') as f:\n",
    "    f.write(\"{\")\n",
    "    for w in range(len(WOWordFreq)):\n",
    "        f.write(f\"\\\"{WOWordFreq['Word'][w]}\\\":{str(WOWordFreq['Frequency'][w])}\")\n",
    "        if w != len(WOWordFreq) - 1:\n",
    "            f.write(',')\n",
    "    f.write(\"}\")\n",
    "\n",
    "spell = SpellChecker(distance = 2)\n",
    "#spell.word_frequency.load_dictionary(\"WOWordFreq.json\")\n",
    "spell.correction('fgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0274b32-19bd-4a0f-b925-36aeaab90ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellChecker(text):\n",
    "    words = text.split(' ')\n",
    "    final = ''\n",
    "    for w in range(len(words)):\n",
    "        suggestions =spell.correction(words[w].lower())\n",
    "        #if suggestions in WOWordFreq['Word'].to_list():\n",
    "            #final = final + suggestions + ' '\n",
    "        final = final + suggestions + ' '\n",
    "        \n",
    "    return final\n",
    "spellingTestList = questData['DrawingTextAll'][probe]\n",
    "spellingTestList = spellChecker(spellingTestList)\n",
    "print(questData['Name'][probe])\n",
    "print(spellingTestList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa957c24-b55e-421a-96db-d83c8caf5806",
   "metadata": {},
   "outputs": [],
   "source": [
    "spellChecked = questData['DrawingTextAll'].apply(spellChecker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0976c9d-e85a-48c4-9458-90665826d744",
   "metadata": {},
   "outputs": [],
   "source": [
    "spellChecked[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddcdb6b-91c1-4585-a7fa-9ab7c608d7e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1>Word2Vec Model using WO Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a3b87-37d1-48a6-92d3-8888b2b363c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WOdata['Edited1'] = [list() for x in range(len(WOdata.index))]\n",
    "WOdata['Edited1'] = WOdata['DESCRIPTION'].apply(processText)\n",
    "WOdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00cbb65e-bdff-40bc-8da6-bb7a3e61b5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = WOdata['Edited1'].to_list()\n",
    "'''\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "'''\n",
    "dictionary = corpora.Dictionary(WOdata['Edited1'])\n",
    "corpus = [dictionary.doc2bow(text) for text in WOdata['Edited1']]\n",
    "#lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d8cb8ba5-e683-4144-8edf-367fa63753cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/8302 is pm\n",
      "word #1/8302 is 1\n",
      "word #2/8302 is 2\n",
      "word #3/8302 is weekly\n",
      "word #4/8302 is unit\n",
      "word #5/8302 is 3\n",
      "word #6/8302 is 4\n",
      "word #7/8302 is daily\n",
      "word #8/8302 is monthly\n",
      "word #9/8302 is oil\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import gensim.models\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences=WOdata['Edited1'].to_list())\n",
    "#min_count\n",
    "#ns_exponent = 0.75 #negative means low-frequency higher than high-fre\n",
    "#trim_rule = lambda x: \n",
    "#sample = threshhold for which-h\n",
    "wv = model.wv\n",
    "#vec_king = model.wv['Coal']\n",
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index ==10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d55e381e-1711-4bc7-b1e5-f1354a9994db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('WOWord2Vec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab610ce-54f4-4835-8efc-b5c15fc67452",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load('WOWord2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fdd3b3fe-adb7-4e92-9edd-3bbc3a6405e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('broken', 0.8694186210632324),\n",
       " ('missing', 0.8669424057006836),\n",
       " ('bent', 0.8198492527008057),\n",
       " ('loose', 0.8186651468276978),\n",
       " ('fell', 0.7903898358345032),\n",
       " ('stripped', 0.7291839718818665),\n",
       " ('sheared', 0.7282971143722534),\n",
       " ('hitting', 0.7082007527351379),\n",
       " ('worn', 0.7074403166770935),\n",
       " ('arm', 0.7035567164421082)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'broke'\n",
    "model.wv.most_similar(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b263b70-39d4-4a21-8186-4c20d4b9f9ff",
   "metadata": {},
   "source": [
    "<h1>Using The WO Word2Vec Model for Similarity in Quest </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ddf1f081-2ed1-4c4d-9d26-0c2cf438c314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coal', 'feed', 'rate', 'indicators']\n"
     ]
    }
   ],
   "source": [
    "#import logging\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "#Need to clean edited1 since i think the noise is hurting the data comparison\n",
    "sentence_1 = processText(\"coal feed rate indicators for\")\n",
    "print(sentence_1)\n",
    "def attempt(target):\n",
    "    return model.wv.wmdistance(sentence_1, target)\n",
    "#questData['Score'] = questData['Edited1'].apply(attempt)\n",
    "questData['Score'] = questData['spellChecked'].apply(attempt)\n",
    "questData = questData.sort_values(\"Score\", ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255df0ca-1fd6-4ad9-9d4a-77a925922a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "questData[['Name','DrawingTextAll','spellChecked']].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c912d5a0-27b6-4d81-a63e-a6e7e10651bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "questData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ebbb30e0-71d9-4bb2-9739-72f83241f363",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>Edited1</th>\n",
       "      <th>Edited2</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10478</th>\n",
       "      <td>MC000CHGVFDJA-MTR</td>\n",
       "      <td>JA Feeder Bolt Loose</td>\n",
       "      <td>[ja, feeder, bolt, loose]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.630830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198072</th>\n",
       "      <td>MC000CHGVFDE2</td>\n",
       "      <td>E2 feeder has a spring bolt loose.</td>\n",
       "      <td>[e2, feeder, spring, bolt, loose]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.731587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167091</th>\n",
       "      <td>MC000PLTXXX</td>\n",
       "      <td>Door Hinge falling apart, screws falling out h...</td>\n",
       "      <td>[door, hinge, falling, apart, screws, falling,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.750803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>TC000PRDXXX</td>\n",
       "      <td>Install loose tray cover</td>\n",
       "      <td>[install, loose, tray, cover]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.825695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153479</th>\n",
       "      <td>TC001ESPRAPXXX</td>\n",
       "      <td>B32-2 Has a Loose Cylinder Clamp might be broke</td>\n",
       "      <td>[b32, 2, has, loose, cylinder, clamp, might, b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.829852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155359</th>\n",
       "      <td>MC000CHGSRC---BOOMCONVY</td>\n",
       "      <td>cancelled redundent</td>\n",
       "      <td>[cancelled, redundent]</td>\n",
       "      <td>[]</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46576</th>\n",
       "      <td>GHCY-S-GLITALLS-GSGLT</td>\n",
       "      <td>VOID</td>\n",
       "      <td>[void]</td>\n",
       "      <td>[]</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195331</th>\n",
       "      <td>MC000STBXXX</td>\n",
       "      <td>\\</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124899</th>\n",
       "      <td>GHAP-CCRGYP01AFFDPMP</td>\n",
       "      <td>HHTRRH</td>\n",
       "      <td>[hhtrrh]</td>\n",
       "      <td>[]</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166617</th>\n",
       "      <td>GH001DCSCOMALLCPUACUPC1</td>\n",
       "      <td>GRIDEX GAMES</td>\n",
       "      <td>[gridex, games]</td>\n",
       "      <td>[]</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218288 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       LOCATION  \\\n",
       "10478         MC000CHGVFDJA-MTR   \n",
       "198072            MC000CHGVFDE2   \n",
       "167091              MC000PLTXXX   \n",
       "242                 TC000PRDXXX   \n",
       "153479           TC001ESPRAPXXX   \n",
       "...                         ...   \n",
       "155359  MC000CHGSRC---BOOMCONVY   \n",
       "46576     GHCY-S-GLITALLS-GSGLT   \n",
       "195331              MC000STBXXX   \n",
       "124899     GHAP-CCRGYP01AFFDPMP   \n",
       "166617  GH001DCSCOMALLCPUACUPC1   \n",
       "\n",
       "                                              DESCRIPTION  \\\n",
       "10478                                JA Feeder Bolt Loose   \n",
       "198072                 E2 feeder has a spring bolt loose.   \n",
       "167091  Door Hinge falling apart, screws falling out h...   \n",
       "242                              Install loose tray cover   \n",
       "153479    B32-2 Has a Loose Cylinder Clamp might be broke   \n",
       "...                                                   ...   \n",
       "155359                                cancelled redundent   \n",
       "46576                                                VOID   \n",
       "195331                                                  \\   \n",
       "124899                                             HHTRRH   \n",
       "166617                                       GRIDEX GAMES   \n",
       "\n",
       "                                                  Edited1 Edited2     Score  \n",
       "10478                           [ja, feeder, bolt, loose]      []  0.630830  \n",
       "198072                  [e2, feeder, spring, bolt, loose]      []  0.731587  \n",
       "167091  [door, hinge, falling, apart, screws, falling,...      []  0.750803  \n",
       "242                         [install, loose, tray, cover]      []  0.825695  \n",
       "153479  [b32, 2, has, loose, cylinder, clamp, might, b...      []  0.829852  \n",
       "...                                                   ...     ...       ...  \n",
       "155359                             [cancelled, redundent]      []       inf  \n",
       "46576                                              [void]      []       inf  \n",
       "195331                                                 []      []       inf  \n",
       "124899                                           [hhtrrh]      []       inf  \n",
       "166617                                    [gridex, games]      []       inf  \n",
       "\n",
       "[218288 rows x 5 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WOdata['Score'] = WOdata['Edited1'].apply(attempt)\n",
    "WOdata.sort_values(\"Score\", ascending = True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3fd445-985e-4b0e-97e9-32c4208e3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quest probing\n",
    "probe = 3\n",
    "print(questData['Name'][probe])\n",
    "print(questData['DrawingTextAll'][probe])\n",
    "print(questData['spellChecked'][probe])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "83671eed-7e7a-4c03-8574-0a30efc96e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ee' in words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd95e1a-7562-4878-9013-c71a4ebc2cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "'ee' in words.words()\n",
    "final = []\n",
    "for w in questData['spellChecked'][probe].split(' '):\n",
    "    if w in words.words():\n",
    "        final.append(w)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9bb1b-f2fd-4aea-9635-93914d54f9c4",
   "metadata": {},
   "source": [
    "<h1> Testing Nmslib Indexer </h1>\n",
    "<a href = 'https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/nmslibtutorial.ipynb'>Lonk</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e89e3c03-70e0-4e31-a04d-6024dff2b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.similarities.nmslib import NmslibIndexer\n",
    "nmslib_index = NmslibIndexer(model, {'M': 100, 'indexThreadQty': 1, 'efConstruction': 100}, {'efSearch': 10})\n",
    "#M and efConstruction is accuracy, but onger indexing\n",
    "#indexThreatQty is nubmer of theready\n",
    "#EfSearch higher is better but longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52ab13a1-8fa7-4565-904e-6c6fee3b6633",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load('WOWord2Vec')\n",
    "#model = gensim.models.Doc2Vec.load('doc2vecWOData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01dad49f-6c03-4822-94fa-0b041aff7e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model.wv[\"absorber\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02c9d33a-494a-4ecd-8b71-1669e40ff919",
   "metadata": {},
   "outputs": [],
   "source": [
    "approximate_neighbors = model.wv.most_similar([vector], topn=11, indexer=nmslib_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf1636b2-c1df-4ce7-8967-4c691938b15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate Neighbors\n",
      "('absorber', 1.0)\n",
      "('abs', 0.7976338863372803)\n",
      "('wfgd', 0.5707395076751709)\n",
      "('fgd', 0.5479655861854553)\n",
      "('agitator', 0.4636227488517761)\n",
      "('agitators', 0.4607580304145813)\n",
      "('arp', 0.436490535736084)\n",
      "('hydrocyclone', 0.4069739580154419)\n",
      "('recycle', 0.4054768681526184)\n",
      "('demineralizer', 0.3975650668144226)\n",
      "('lst', 0.39382314682006836)\n"
     ]
    }
   ],
   "source": [
    "print(\"Approximate Neighbors\")\n",
    "for neighbor in approximate_neighbors:\n",
    "    print(neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5dbb350e-7b56-4234-bf95-6447dc1a9d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normal (not nmslib-indexed) Neighbors\n",
      "('fgd', 1.0)\n",
      "('abs', 0.6093549728393555)\n",
      "('absorber', 0.5479655265808105)\n",
      "('wfgd', 0.4383356273174286)\n",
      "('bromine', 0.4138839542865753)\n",
      "('eliminator', 0.40072569251060486)\n",
      "('hydrocyclone', 0.37773463129997253)\n",
      "('cw', 0.3742797374725342)\n",
      "('scrubber', 0.3714107275009155)\n",
      "('lpsw', 0.36952903866767883)\n",
      "('pier', 0.3678264021873474)\n"
     ]
    }
   ],
   "source": [
    "normal_neighbors = model.wv.most_similar([vector], topn=11)\n",
    "print(\"\\nNormal (not nmslib-indexed) Neighbors\")\n",
    "for neighbor in normal_neighbors:\n",
    "    print(neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79994d-c939-4307-ab39-8a6a05dec212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WOsearch = WOdata\n",
    "sentence_1 = processText(\"fgd\")\n",
    "print(sentence_1)\n",
    "def attempt(target):\n",
    "    return model.wv.wmdistance(sentence_1, target, indexer=nmslib_index)\n",
    "#questData['Score'] = questData['Edited1'].apply(attempt)\n",
    "WOsearch['Score'] = WOsearch['Edited1'].apply(attempt)\n",
    "WOsearch = WOsearch.sort_values(\"Score\", ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905622d3-7f8b-4abb-9e03-6e6c158db5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "WOsearch['Score'] = WOsearch['Edited1'].apply(attempt)\n",
    "WOsearch.sort_values(\"Score\", ascending = True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa29be40-a2c9-4c8e-a560-80caf0b9dda1",
   "metadata": {},
   "source": [
    "<h1> Word Filter? </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "08085285-eba3-4f95-9fe8-5662f2231e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acronyms = []\n",
    "with open('words/acronyms.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        acronyms.append(line.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d3794-4416-4e76-9bcc-fcce228efe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "woWords = []\n",
    "with open('words/CutWOWordFreq.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        woWords.append(line.split(' ')[0])\n",
    "#woWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d162609-f2ba-4149-95c1-e542a74c9efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1572"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acronyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2710c4e8-ee49-43b6-9dba-634b753452a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237481"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words.union(set(acronyms + woWords + words.words())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0be31812-6da9-44b1-8b7f-ea55e352a03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237315"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(acronyms + words.words()).union(stop_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f5c5ca1-4bf0-46bc-910e-849b009ef5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedFreq = pd.read_csv(\"words/FullCombinedFreq.txt\", sep=' ', header = None)\n",
    "combinedFreq.sort_values(1, ascending = False)\n",
    "combindedFreq[0].values[102520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "897aa4bf-322f-4111-980f-59f2a87dcb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "symSpellDict = pd.read_csv(\"words/SymSpellDict_en_82_765.txt\", sep=' ', header = None)\n",
    "WOWordFreq = pd.read_csv(\"words/SCWOWordFreq.txt\", sep=' ', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b6b0f-c0d8-4893-b80c-19649d567ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-16 11:30:53.837951\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "questData['Filetered'] = questData['Edited1'].apply(lambda x : [w for w in x if w in set(acronyms + words.words())])\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c805a708-ce3b-4407-92d8-8bcae3ec9f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>ee</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "3649  ee  2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WOWordFreq[WOWordFreq[0] == 'ee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ca323527-130e-4ffb-aee4-011774f2429b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93243"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinedFreq[0].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "61bf4e34-5121-464f-8d5b-a2afd779b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ed893a74-03c5-4371-af31-1a8721553080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'dimension' in words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48548c32-8765-4a35-bd71-e1218330d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = questData.iloc[round(random.random()*1000)]\n",
    "print(p['DrawingTextAll'])\n",
    "p['Name']\n",
    "#3231905\n",
    "#3129769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99bf2b0-daf9-4c1f-a3bc-f6547300a099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c302180-0b6d-4462-b0e0-be9b3d4b1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "#p = questData['DrawingTextAll'][0]\n",
    "split = p['DrawingTextAll'].split(' ')\n",
    "def filter(word):\n",
    "    if word in set(acronyms + words.words()) or word.isupper():\n",
    "        return word\n",
    "' '.join([w for w in split if w.lower() in (set(acronyms + words.words()) or w.isupper()) and len(w) > 2 ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb6f05c-51e5-4643-aded-ca405316c102",
   "metadata": {},
   "source": [
    "<h1>Queries!</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e360d0de-677a-437b-af2a-0d7081f421e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import gensim\n",
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "def processText(text):\n",
    "    #text_tokens = word_tokenize(text)\n",
    "    text_tokens = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(text)\n",
    "    text_tokens = [word for word in text_tokens if not word in stop_words]  ##Remove Stop Words\n",
    "    text_tokens = [word.lower() for word in text_tokens]\n",
    "    #text_tokens = [ps.stem(word) for word in text_tokens] #Stem Words\n",
    "    #text_tokens = [word for word in text_tokens if len(word) > 2] #Removing noise\n",
    "    #text_tokens = [word for word in text_tokens if word.isalpha()] #Remove Punctuation\n",
    "    #text_tokens = [ele for ele in text_tokens if ele.strip()] #remove empty spaces in list\n",
    "    return text_tokens\n",
    "#Applying Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8e38258e-ad11-427d-9431-b5589e989b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = r''\n",
    "dbSQL = ''\n",
    "user = ''\n",
    "pwd = ''\n",
    "\n",
    "woSelect= f\"\"\"SELECT [WONUM]\n",
    "      ,[LOCATION]\n",
    "      ,[DESCRIPTION]\n",
    "  FROM [Generation].[agent].[MaximoWorkOrders]\n",
    "  Where cast(STATUSDATE as date) > '01/01/2020'\n",
    "\"\"\"  #and LOC = 'MC'\n",
    "#  And ({where})\"\"\"\n",
    "\n",
    "#getting data and then relableing maximo location to higher level equipment name\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+host+';DATABASE='+dbSQL+';UID='+user+';PWD='+ pwd)\n",
    "WOdata = pd.read_sql(woSelect, cnxn)\n",
    "WOdata = WOdata.drop(columns=['WONUM'])\n",
    "#WOdata.head()\n",
    "WOdata['Edited1'] = [list() for x in range(len(WOdata.index))]\n",
    "WOdata['Edited1'] = WOdata['DESCRIPTION'].apply(processText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "202f9fb2-a282-46ab-bc4e-fb3eb38ba583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark/.local/lib/python3.8/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size:  DrawingID         5000\n",
      "Name              5000\n",
      "DrawingTextAll    5000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "query1 = \"\"\"Select TOP(5000) [DrawingID], [Name], [DrawingTextAll]  from [Generation].[quest].[Drawings] WHERE DrawingTextAll IS NOT NULL\"\"\"\n",
    "queryProperties ={\"user\": \"\", \"password\": \"\", \"driver\":\"org.postgresql.Driver\",\"spark.jars\":\"file:/home/postgresTest/postgresql-42.2.9.jar\",\"spark.executor.extraClassPath\":\"/home/postgresTest/postgresql-42.2.9.jar\",\"spark.driver.extraClassPath\":\"/home/postgresTest/postgresql-42.2.9.jar\", 'partitionColumn':'TAGID_PI', 'lowerBound': '1100000000' , 'upperBound': '1510890005', 'numPartitions':'80', 'fetchsize':'100000'}\n",
    "server = '' \n",
    "database = '' \n",
    "username = '' \n",
    "password = ''\n",
    "cnxn = pyodbc.connect('DRIVER=/opt/microsoft/msodbcsql17/lib64/libmsodbcsql-17.10.so.1.1;SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "#You may need to change the libmsodbcsql-17.8.s0.1.1 if we update it. Open a terminal cd out of /u01/ and start going down opt\n",
    "global questData\n",
    "questData = pd.read_sql(query1,cnxn)\n",
    "print(\"Data size: \", questData.count())\n",
    "cnxn.close()\n",
    "\n",
    "questData['Edited1'] = [list() for x in range(len(questData.index))]\n",
    "questData['Edited1'] = questData['DrawingTextAll'].apply(processText)\n",
    "#questData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61766e6-f084-4908-8064-44195ba853bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1>Word2Vec Model using WO Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42d98724-5ed7-418e-85bc-90aad08f0da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = WOdata['Edited1'].to_list()\n",
    "frequency = defaultdict(int)\n",
    "'''\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "'''\n",
    "dictionary = corpora.Dictionary(WOdata['Edited1'])\n",
    "corpus = [dictionary.doc2bow(text) for text in WOdata['Edited1']]\n",
    "#lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce583525-bba5-4a3a-a7fb-c39b4848ed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/8282 is pm\n",
      "word #1/8282 is 1\n",
      "word #2/8282 is 2\n",
      "word #3/8282 is weekly\n",
      "word #4/8282 is unit\n",
      "word #5/8282 is 3\n",
      "word #6/8282 is 4\n",
      "word #7/8282 is daily\n",
      "word #8/8282 is monthly\n",
      "word #9/8282 is oil\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import gensim.models\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences=WOdata['Edited1'].to_list())\n",
    "#min_count\n",
    "#ns_exponent = 0.75 #negative means low-frequency higher than high-fre\n",
    "#trim_rule = lambda x: \n",
    "#sample = threshhold for which-h\n",
    "wv = model.wv\n",
    "#vec_king = model.wv['Coal']\n",
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index ==10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f30c0683-b890-4df6-a6a2-0b611cb5bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('WOWord2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c675550-16c4-47e9-b52e-956391495f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = gensim.models.Word2Vec.load('WOWord2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7f406802-60ee-4c24-854c-49300a9e3157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('strainer', 0.4090183973312378),\n",
       " ('transformer', 0.38260534405708313),\n",
       " ('hotwell', 0.3825652599334717),\n",
       " ('aux', 0.37659013271331787),\n",
       " ('turbine', 0.3743785321712494),\n",
       " ('gsu', 0.3703068494796753),\n",
       " ('corner', 0.36861276626586914),\n",
       " ('lpsw', 0.36482277512550354),\n",
       " ('2nd', 0.35992324352264404),\n",
       " ('hydrogen', 0.34742212295532227)]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'main'\n",
    "wv = model.wv\n",
    "wv.most_similar(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9488df-7e44-4cde-9be6-d4e006f56232",
   "metadata": {},
   "source": [
    "<h1>Using The WO Word2Vec Model for Similarity in Quest </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac23664-f165-413f-9e41-b13ec7d24cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import logging\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "#Need to clean edited1 since i think the noise is hurting the data comparison\n",
    "sentence_1 = processText(\"\")\n",
    "print(sentence_1)\n",
    "def attempt(target):\n",
    "    return model.wv.wmdistance(sentence_1, target)\n",
    "questData['Score'] = questData['Edited1'].apply(attempt)\n",
    "questScores = questData.sort_values(\"Score\", ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d9b512-f4e6-4911-9e37-0624a284df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "questScores[['Name','DrawingTextAll']].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "109bff45-d7a8-4bea-a1c6-8b6b49ae91c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>Edited1</th>\n",
       "      <th>Edited2</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10478</th>\n",
       "      <td>MC000CHGVFDJA-MTR</td>\n",
       "      <td>JA Feeder Bolt Loose</td>\n",
       "      <td>[ja, feeder, bolt, loose]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.630830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198072</th>\n",
       "      <td>MC000CHGVFDE2</td>\n",
       "      <td>E2 feeder has a spring bolt loose.</td>\n",
       "      <td>[e2, feeder, spring, bolt, loose]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.731587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167091</th>\n",
       "      <td>MC000PLTXXX</td>\n",
       "      <td>Door Hinge falling apart, screws falling out h...</td>\n",
       "      <td>[door, hinge, falling, apart, screws, falling,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.750803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>TC000PRDXXX</td>\n",
       "      <td>Install loose tray cover</td>\n",
       "      <td>[install, loose, tray, cover]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.825695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153479</th>\n",
       "      <td>TC001ESPRAPXXX</td>\n",
       "      <td>B32-2 Has a Loose Cylinder Clamp might be broke</td>\n",
       "      <td>[b32, 2, has, loose, cylinder, clamp, might, b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.829852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155359</th>\n",
       "      <td>MC000CHGSRC---BOOMCONVY</td>\n",
       "      <td>cancelled redundent</td>\n",
       "      <td>[cancelled, redundent]</td>\n",
       "      <td>[]</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46576</th>\n",
       "      <td>GHCY-S-GLITALLS-GSGLT</td>\n",
       "      <td>VOID</td>\n",
       "      <td>[void]</td>\n",
       "      <td>[]</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195331</th>\n",
       "      <td>MC000STBXXX</td>\n",
       "      <td>\\</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124899</th>\n",
       "      <td>GHAP-CCRGYP01AFFDPMP</td>\n",
       "      <td>HHTRRH</td>\n",
       "      <td>[hhtrrh]</td>\n",
       "      <td>[]</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166617</th>\n",
       "      <td>GH001DCSCOMALLCPUACUPC1</td>\n",
       "      <td>GRIDEX GAMES</td>\n",
       "      <td>[gridex, games]</td>\n",
       "      <td>[]</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218288 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       LOCATION  \\\n",
       "10478         MC000CHGVFDJA-MTR   \n",
       "198072            MC000CHGVFDE2   \n",
       "167091              MC000PLTXXX   \n",
       "242                 TC000PRDXXX   \n",
       "153479           TC001ESPRAPXXX   \n",
       "...                         ...   \n",
       "155359  MC000CHGSRC---BOOMCONVY   \n",
       "46576     GHCY-S-GLITALLS-GSGLT   \n",
       "195331              MC000STBXXX   \n",
       "124899     GHAP-CCRGYP01AFFDPMP   \n",
       "166617  GH001DCSCOMALLCPUACUPC1   \n",
       "\n",
       "                                              DESCRIPTION  \\\n",
       "10478                                JA Feeder Bolt Loose   \n",
       "198072                 E2 feeder has a spring bolt loose.   \n",
       "167091  Door Hinge falling apart, screws falling out h...   \n",
       "242                              Install loose tray cover   \n",
       "153479    B32-2 Has a Loose Cylinder Clamp might be broke   \n",
       "...                                                   ...   \n",
       "155359                                cancelled redundent   \n",
       "46576                                                VOID   \n",
       "195331                                                  \\   \n",
       "124899                                             HHTRRH   \n",
       "166617                                       GRIDEX GAMES   \n",
       "\n",
       "                                                  Edited1 Edited2     Score  \n",
       "10478                           [ja, feeder, bolt, loose]      []  0.630830  \n",
       "198072                  [e2, feeder, spring, bolt, loose]      []  0.731587  \n",
       "167091  [door, hinge, falling, apart, screws, falling,...      []  0.750803  \n",
       "242                         [install, loose, tray, cover]      []  0.825695  \n",
       "153479  [b32, 2, has, loose, cylinder, clamp, might, b...      []  0.829852  \n",
       "...                                                   ...     ...       ...  \n",
       "155359                             [cancelled, redundent]      []       inf  \n",
       "46576                                              [void]      []       inf  \n",
       "195331                                                 []      []       inf  \n",
       "124899                                           [hhtrrh]      []       inf  \n",
       "166617                                    [gridex, games]      []       inf  \n",
       "\n",
       "[218288 rows x 5 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WOdata['Score'] = WOdata['Edited1'].apply(attempt)\n",
    "WOdata.sort_values(\"Score\", ascending = True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fccd01-402f-4e6a-869e-47c4553b6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quest probing\n",
    "questData['DrawingTextAll'][3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433cf276-1c0f-4458-831c-864a146f6b8a",
   "metadata": {},
   "source": [
    "<h1>Building off a Pretrained Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40fb38e1-9d64-4107-92d7-1d0dab57439f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mode.train(update, total_examples = len(update)), use this variation if we use a pretrain model.\n",
    "#pretrained models https://github.com/RaRe-Technologies/gensim-data\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "#convert file to w2v readable | i lied jus do it straight\n",
    "#tmp = KeyedVectors.load_word2vec_format('pretrained/numberbatch-en-19.08.txt.gz')\n",
    "#tmp.save_word2vec_format('pretrained/W2Vnumberbatch-en-19.08')\n",
    "#tmp = KeyedVectors.load_word2vec_format('pretrained/glove.6B.50d.txt', no_header= True)\n",
    "#tmp.save_word2vec_format('pretrained/W2Vglove.6B.50d.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "561a6604-e5f9-424b-8204-f073dcd15baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrainedWV = gensim.models.Word2Vec()\n",
    "pretrainedWV.wv = pretrainedWV.wv.load_word2vec_format('pretrained/glove-twitter-50.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5f22cdf-ea9f-4923-ad2b-c5bf2490677b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tests', 0.916435718536377),\n",
       " ('testing', 0.8199220299720764),\n",
       " ('tested', 0.7442875504493713),\n",
       " ('final', 0.6910227537155151),\n",
       " ('taking', 0.687900185585022),\n",
       " ('results', 0.6846890449523926),\n",
       " ('match', 0.6769682168960571),\n",
       " ('determine', 0.6767976880073547),\n",
       " ('challenge', 0.6747705340385437),\n",
       " ('selection', 0.6724263429641724)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrainedWV.wv.most_similar('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "244d872b-d718-45cf-9840-d7b35a4bdc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab': 200000000,\n",
       " 'vectors': 160000000,\n",
       " 'syn1neg': 160000000,\n",
       " 'total': 520000000}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrainedWV.estimate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5d670db-e7c1-47a5-9f4c-44c1a9def391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lights',\n",
       " 'do',\n",
       " 'not',\n",
       " 'work',\n",
       " 'at',\n",
       " 'compressor',\n",
       " 'station',\n",
       " 'making',\n",
       " 'it',\n",
       " 'unsafe',\n",
       " 'to',\n",
       " 'work',\n",
       " 'at',\n",
       " 'night']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_corpus(f, tokens_only=False):\n",
    "    for i, line in enumerate(f):\n",
    "        if tokens_only:\n",
    "            yield line\n",
    "        else:\n",
    "            # For training data, add tags\n",
    "            #unique tag\n",
    "            yield gensim.models.doc2vec.TaggedDocument(line, [i])\n",
    "train_corpus = list(read_corpus(WOdata['Edited1'].tolist(), tokens_only=True))\n",
    "train_corpus[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5e8877b-def2-4a8e-8a53-f0495c2535e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "Exception in thread Thread-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "Exception in thread Thread-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "        self.run()self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "            self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/spark/.local/lib/python3.8/site-packages/gensim/models/word2vec.py\", line 1163, in _worker_loop\n",
      "self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/spark/.local/lib/python3.8/site-packages/gensim/models/word2vec.py\", line 1163, in _worker_loop\n",
      "self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/spark/.local/lib/python3.8/site-packages/gensim/models/word2vec.py\", line 1163, in _worker_loop\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, alpha, thread_private_mem)\n",
      "  File \"/home/spark/.local/lib/python3.8/site-packages/gensim/models/word2vec.py\", line 954, in _do_train_job\n",
      "        tally, raw_tally = self._do_train_job(data_iterable, alpha, thread_private_mem)\n",
      "  File \"/home/spark/.local/lib/python3.8/site-packages/gensim/models/word2vec.py\", line 954, in _do_train_job\n",
      "tally, raw_tally = self._do_train_job(data_iterable, alpha, thread_private_mem)    \n",
      "  File \"/home/spark/.local/lib/python3.8/site-packages/gensim/models/word2vec.py\", line 954, in _do_train_job\n",
      "    tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)    \n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 632, in gensim.models.word2vec_inner.train_batch_cbow\n",
      "tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 632, in gensim.models.word2vec_inner.train_batch_cbow\n",
      "\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 632, in gensim.models.word2vec_inner.train_batch_cbow\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 479, in gensim.models.word2vec_inner.init_w2v_config\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 479, in gensim.models.word2vec_inner.init_w2v_config\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 479, in gensim.models.word2vec_inner.init_w2v_config\n",
      "AttributeErrorAttributeError: 'KeyedVectors' object has no attribute 'vectors_lockf': 'KeyedVectors' object has no attribute 'vectors_lockf'\n",
      "\n",
      "AttributeError: 'KeyedVectors' object has no attribute 'vectors_lockf'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-5457441cc812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#pretrainedWV.build_vocab(train_corpus, update = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpretrainedWV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrainedWV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcorpus_iterable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[0m\u001b[1;32m   1071\u001b[0m                     \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m                     \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[0m\u001b[1;32m   1432\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_corpus_file_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#pretrainedWV.build_vocab(train_corpus, update = True)\n",
    "pretrainedWV.train(train_corpus, total_examples=pretrainedWV.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5fefd4-637e-4c44-a087-15ccff13815d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05ab93c8-3f63-4b8a-88ef-0cfa8e6c786e",
   "metadata": {},
   "source": [
    "<h1>Doc2Vec Model Using WO Data </h1> <br> <h2> Note: Model Variable gets overwritten here </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "839c8544-a832-4e3c-b1e8-865634d92fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I believe the next step is to somehow convert words to vectors and then use doc2bow?\n",
    "def read_corpus(f, tokens_only=False):\n",
    "    for i, line in enumerate(f):\n",
    "        if tokens_only:\n",
    "            yield line\n",
    "        else:\n",
    "            # For training data, add tags\n",
    "            #unique tag\n",
    "            yield gensim.models.doc2vec.TaggedDocument(line, [i])\n",
    "train_corpus = list(read_corpus(WOdata['Edited1'].tolist()))\n",
    "test_corpus = list(read_corpus(WOdata['Edited1'].tolist(), tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb94266-7d8b-4009-8e85-7284fce5c73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'fgd' appeared 4031 times in the training corpus.\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=200, epochs=40, workers = 6, dbow_words = 1)\n",
    "model.build_vocab(train_corpus)\n",
    "print(f\"Word 'fgd' appeared {model.wv.get_vecattr('fgd', 'count')} times in the training corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c2049-0fc4-45bf-a24a-937bca6477d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-16 11:40:16.584662\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa1044-392a-4912-8177-37dfc00aa25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/doc2vecWOData4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb4ecd10-14de-4fd5-89f6-298ffe42527d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.7707538e-01  1.7196430e-01  7.7650979e-02  1.2922162e-01\n",
      "  1.1668090e-01 -6.8112776e-02  2.1427324e-01 -1.6797665e-01\n",
      " -3.6510028e-02 -2.7097240e-01  7.9751320e-02 -2.6792899e-01\n",
      " -2.9787445e-01 -1.0617851e-01  1.9787905e-01 -1.9451378e-02\n",
      " -1.6370017e-02  3.7663415e-01 -6.7968644e-02 -1.6176629e-01\n",
      " -1.5798238e-01 -2.5356320e-01  3.8365823e-01 -8.5397065e-02\n",
      "  2.7064833e-01 -1.4149140e-01 -1.0598338e-01  2.6059416e-01\n",
      "  9.2642859e-02  1.1111005e-01 -2.7634421e-01  2.2231697e-01\n",
      " -3.1300426e-01  4.4888649e-02  8.0682479e-02 -1.8360110e-01\n",
      " -9.0924673e-02  1.0564238e-02  6.9180995e-02  1.2791516e-01\n",
      " -1.3405484e-01  5.9572875e-02 -6.9165598e-03  4.8322836e-01\n",
      "  5.2957665e-02 -2.7443886e-02 -2.8485894e-01  6.3668601e-02\n",
      "  1.2153303e-01  9.3278416e-02 -1.2861562e-01 -2.8943521e-01\n",
      " -2.4067245e-01 -2.2818142e-01  7.1851127e-02 -1.1227820e-01\n",
      " -1.4802501e-01  1.7341290e-01 -9.1604225e-02 -8.6124495e-02\n",
      "  5.9597690e-02 -2.6148386e-02 -1.2535244e-01  2.0192073e-01\n",
      " -1.1154042e-02 -6.7520320e-02  2.0274863e-01 -2.5919017e-01\n",
      " -3.0145338e-01  6.2663101e-02 -3.8328186e-01  1.7435439e-01\n",
      " -2.5715268e-01  3.3023518e-02  1.6778833e-01  4.7009770e-02\n",
      " -5.9856139e-03  3.3505380e-01  4.3365296e-02  3.0311793e-01\n",
      " -9.3717627e-02  6.1196435e-02 -6.0839627e-02 -1.1831712e-01\n",
      "  2.3660657e-01 -1.8735553e-01 -2.5441307e-01 -6.6265531e-02\n",
      "  3.4449548e-01 -1.6569920e-01  2.5432205e-01  3.0368498e-01\n",
      " -2.8560555e-01 -1.5247974e-04 -8.9786053e-02 -1.5612796e-01\n",
      "  1.5116735e-01 -2.0416231e-01  7.9969414e-02 -9.4012514e-02]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['coal', 'failure'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d5520dd-ceba-4dba-a2ce-c83bd713508b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-cae1a4bdcef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minferred_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minferred_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdocid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mranks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#This will lietrally take forerver as it iterates through EVERY god dang document\n",
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e477ee-48b4-43d3-8065-11ae4bd9651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba91441f-db19-4af3-8b13-dfd259b0a713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document : «leaking flue gas»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/m,d100,n5,w5,mc200,s0.001,t6>:\n",
      "\n",
      "MOST (8883, 0.819263756275177): «1b14 upper lower demister wash lances leaking flue gas long description»\n",
      "\n",
      "SECOND-MOST (198105, 0.7437318563461304): «2f5 gas gun gas leak i e currently working»\n",
      "\n",
      "MEDIAN (35128, 0.2091902643442154): «pm 2mo prc5 vla battery bimonthly inspection emergency 2 rack 2 battery 60 cell»\n",
      "\n",
      "LEAST (60290, -0.38988199830055237): «cbu bin scale keeps jumping around dcs»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = processText('LEAKING FLUE GAS')\n",
    "vector = model.infer_vector(words)\n",
    "close = model.dv.most_similar([vector], topn= len(model.dv))\n",
    "print('Document : «{}»\\n'.format(' '.join(words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(close)//2), ('LEAST', len(close) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, close[index], ' '.join(train_corpus[close[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b85acd-9a9c-4d37-809b-ff70b8f4e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range (20):\n",
    "    print(' '.join(train_corpus[close[x][0]].words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "978c9ed9-61da-43fe-92c1-82a5bb95ac7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adjustments', 0.2501208782196045),\n",
       " ('secondary', 0.22952206432819366),\n",
       " ('4d', 0.21827472746372223),\n",
       " ('scraper', 0.21001039445400238),\n",
       " ('gpp', 0.20365260541439056),\n",
       " ('bc', 0.19201752543449402),\n",
       " ('furnance', 0.19150449335575104),\n",
       " ('controls', 0.18593253195285797),\n",
       " ('stacker', 0.18368302285671234),\n",
       " ('chain', 0.18204587697982788),\n",
       " ('link', 0.18041753768920898),\n",
       " ('taps', 0.17732341587543488),\n",
       " ('conveying', 0.17592525482177734),\n",
       " ('gh4', 0.17162558436393738),\n",
       " ('sampler', 0.16920390725135803),\n",
       " ('sh', 0.16713185608386993),\n",
       " ('1a', 0.16700418293476105),\n",
       " ('4e', 0.1615622192621231),\n",
       " ('tension', 0.1570001244544983),\n",
       " ('bu', 0.1567893773317337),\n",
       " ('d1', 0.1561805158853531),\n",
       " ('assembly', 0.15269000828266144),\n",
       " ('4c', 0.15129363536834717),\n",
       " ('drop', 0.1504749208688736),\n",
       " ('and', 0.14654284715652466),\n",
       " ('rotary', 0.14566394686698914),\n",
       " ('stay', 0.14513395726680756),\n",
       " ('year', 0.14168427884578705),\n",
       " ('conveyors', 0.14159643650054932),\n",
       " ('tc2b', 0.13662667572498322)]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['primary']\n",
    "vector = model.infer_vector(words)\n",
    "model.wv.most_similar([vector], topn= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6c5f128-327c-49ab-8cd4-be5698944e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_output_word([''])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e827b5fd-7de3-4416-bc97-4a67632fdd7b",
   "metadata": {},
   "source": [
    "<h1> Doc2VecTesting </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98acd357-2285-4ea6-bdba-ecbc97e95d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SDRS MODULE MISC//THE WEGD DOOR D253 WEST SIDE LANDING 5 IS LEAKING FLUE GAS'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "WOdata['DESCRIPTION'][round(random.random()*231995)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43f4b4e-14e0-42c1-9a63-35396db5b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = round(random.random()*4999)\n",
    "print(t)\n",
    "print(questData.iloc[t]) #Use name for indexer\n",
    "print(questData.iloc[t][0])\n",
    "print(questData.iloc[t][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8391ae68-cb47-4b6a-8280-e6b66acd4f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fgd']\n"
     ]
    }
   ],
   "source": [
    "sentence_1 = processText(\"fgd\")\n",
    "print(sentence_1)\n",
    "def attempt(target):\n",
    "    return model.wv.wmdistance(sentence_1, target)\n",
    "#questData['Score'] = questData['Edited1'].apply(attempt)\n",
    "questData['Score'] = questData['Edited1'].apply(attempt)\n",
    "questData = questData.sort_values(\"Score\", ascending = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e6eb6df8-68f6-4a02-9bb3-d47aaae183ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(questData.index).index(2506)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626cdb6-7885-4d5c-8b71-2033df4bcba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#questData['DrawingTextAll'] goes by the name (orignal index)\n",
    "questData.iloc[7][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff48e03-de9e-4c84-9dbe-eaa7647c65bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9af5b39-16fa-4526-8d11-900bebe10e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "questData.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbc6b0-ba43-463f-b92a-0b0f4dfed264",
   "metadata": {},
   "source": [
    "<h1>Whoosh </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5513b47f-cee4-4674-b65e-371dedd2ea28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents added\n"
     ]
    }
   ],
   "source": [
    "from whoosh.index import create_in\n",
    "from whoosh.fields import Schema, TEXT, ID\n",
    "from whoosh.index import open_dir\n",
    "import os\n",
    "schema = Schema(id = ID(stored=True), name=TEXT(stored=True), text=TEXT(stored=True))\n",
    "if not os.path.exists(\"documents\"):\n",
    "    os.mkdir(\"documents\")\n",
    "global ix\n",
    "global writer\n",
    "ix = create_in(\"documents\", schema)\n",
    "\n",
    "ix = open_dir(\"documents\")\n",
    "writer = ix.writer()\n",
    "\n",
    "for index, row in questData.iterrows():\n",
    "    writer.add_document(id = str(row.DrawingID).replace('-',' '), name = row.Name, text=row.DrawingTextAll)\n",
    "print('Documents added')\n",
    "writer.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "a1218394-7a36-4714-a275-d3eca9ed8b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<Top 0 Results for <_NullQuery> runtime=8.279801113530993e-05>\n",
      "MIN AU\n"
     ]
    }
   ],
   "source": [
    "from whoosh.query import *\n",
    "from whoosh.qparser import QueryParser\n",
    "ret = []\n",
    "\n",
    "with ix.searcher() as searcher:\n",
    "    nameInput = ''\n",
    "    print(nameInput)\n",
    "    parser = QueryParser('name',ix.schema)\n",
    "    myquery = parser.parse(nameInput)\n",
    "    nameResults = searcher.search(myquery)\n",
    "    print(nameResults)\n",
    "    #text\n",
    "    textInput = 'MIN AU'\n",
    "    print(textInput)\n",
    "    parser = QueryParser(\"text\", ix.schema)\n",
    "    myquery = parser.parse(textInput)\n",
    "    textResults = searcher.search(myquery)\n",
    "    nameResults.upgrade_and_extend(textResults)\n",
    "    for r in range(nameResults.scored_length()):\n",
    "        box = []\n",
    "        hold = nameResults[r]\n",
    "        box.append(hold['id'])\n",
    "        box.append(hold['name'])\n",
    "        box.append(hold['text'])\n",
    "        ret.append(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d26b7-a0cd-4823-9640-61d1d8eb5b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b2997a-8fb5-4404-b60b-ade5b5090bca",
   "metadata": {},
   "source": [
    "<h1> Loading Goggle and trying to train off it </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea0ebe-48e5-49c6-a0c3-6b52ebde7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='pretrained/GoogleNews-vectors-negative300.bin.gz'\n",
    "from gensim.models import KeyedVectors\n",
    "#model = KeyedVectors.load_word2vec_format(path, binary=True, limit=20000)\n",
    "model =  KeyedVectors.load_word2vec_format('pretrained/GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "41ee2198-f1fd-47ef-831b-d876f69f9700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DrawingID                                                   3231700\n",
       "Name              Drawing-Mill Creek-MC4-PI-35-1-PIPING ISOMETRI...\n",
       "DrawingTextAll        5 v7 4 opr a Wore S i0 O LOTATE Dia Gonitc...\n",
       "Edited1           [5, v7, 4, opr, wore, s, i0, o, lotate, dia, g...\n",
       "Score                                                      1.387016\n",
       "Name: 751, dtype: object"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questData.iloc[round(random.random()*4999)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db697b-5816-4f76-8e8b-d1639189fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawingID = 3130637\n",
    "authToken = GetAuthToken()\n",
    "contextID = GetContextID(drawingID, authToken)\n",
    "url=\"\"\n",
    "headers = {'content-type': 'text/xml', 'SOAPAction': ''}\n",
    "body = u\"\"\"\"\"\"\n",
    "response = requests.post(url,data=body,headers=headers,verify=False)\n",
    "response.raise_for_status()\n",
    "#Of my sample size of 2, all \"Catagories\" stat with 174\n",
    "#all \"COntent\" starts wit 072\n",
    "#Some extra datta under 055???\n",
    "metaData = [drawingID]\n",
    "#print(drawingID)\n",
    "for chunk in response.iter_content(1024):\n",
    "    if \"Drawing Number\" in str(chunk):\n",
    "        print('yes')\n",
    "        data = str(chunk).split('\\\\\\\\')\n",
    "        #print(data)\n",
    "        #SOmehow get disciplin\n",
    "        try:\n",
    "            metaData.append(data[data.index('174Company') + 1][3:])\n",
    "        except:\n",
    "            metaData.append('null')\n",
    "        try:\n",
    "            metaData.append(data[data.index('174Document Source') + 1][3:])\n",
    "        except:\n",
    "            metaData.append('null')\n",
    "        try:\n",
    "            metaData.append(data[data.index('174Manufacturer') + 1][3:])\n",
    "        except:\n",
    "            metaData.append('null')\n",
    "        try:\n",
    "            plant = data[data.index('174Plant') + 1][3:]\n",
    "            if 'Trimble County' in plant:\n",
    "                plant = 'TC'\n",
    "            elif 'Mill Creek' in plant:\n",
    "                plant = 'MC'\n",
    "            elif 'Ghent' in plant:\n",
    "                plant = 'GH'\n",
    "            elif 'Cane Run' in plant:\n",
    "                plant = 'CR'\n",
    "            elif 'Brown' in plant:\n",
    "                plant = 'BR'\n",
    "            elif 'Paddy' in plant:\n",
    "                plant = 'PR'\n",
    "            else:\n",
    "                plant = 'null'\n",
    "            metaData.append(plant)   \n",
    "        except:\n",
    "            metaData.append('null')\n",
    "        try:\n",
    "           metaData.append(data[data.index('174Unit') + 1][3:4])\n",
    "        except:\n",
    "            metaData.append('null')\n",
    "        try:\n",
    "            metaData.append(data[data.index('174Project Number') + 1][3:])\n",
    "            try:\n",
    "               int(data[data.index('174Project Number') + 2][3:])\n",
    "               metaData[6] += '-' + data[data.index('174Project Number') + 2][3:]\n",
    "            except:\n",
    "               t = 1\n",
    "        except:\n",
    "            metaData.append('null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2be628c1-31b5-475d-8f31-1fe23bebb84e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-5255d5d095a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "t[2] = 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
